# 基于 LLM 的智能广告审核系统设计与实现

## 引言

在当今数字化时代，广告内容的合规性审核变得越来越重要。传统的人工审核方式不仅耗时耗力，而且容易出现疏漏。如何利用人工智能技术，特别是大语言模型（LLM）来提高审核效率和准确性，成为了一个亟待解决的问题。本文将详细介绍一个基于 LLM 的智能广告审核系统的设计与实现过程。

## 系统架构

### 1. 整体架构

该系统采用模块化设计，主要包含以下核心组件：

- 场景识别模块：自动识别文档类型和审核场景
- 规则解析模块：将法规文本转换为结构化规则
- 工具集成模块：提供文本识别、图片比较等功能
- ReAct 控制模块：协调各模块工作并生成最终分析结果

### 2. 关键技术

系统使用了以下关键技术：

1. ReAct 架构：实现复杂任务的分步推理和执行
2. 多模态分析：结合文本和图像的综合分析
3. 规则引擎：灵活的规则匹配和验证机制
4. 错误处理：多层级的异常处理和恢复机制

## 核心模块实现

### 1. 场景识别模块

场景识别模块负责识别文档类型和具体审核场景。以下是关键实现：

```python
async def identify_scene(self, text_data: str, image_info: Dict[str, Any]) -> Dict[str, Any]:
    """识别文档场景"""
    try:
        # 使用视觉模型分析图片内容
        image_result = await self._execute_vl_chat({
            "file": image_info.get("file", ""),
            "prompt": "分析图片中的产品类型、标签位置和主要文字内容"
        })
        
        # 分析文本特征
        scene_type = "unknown"
        product_type = "unknown"
        specific_scene = "unknown"
        confidence = 0.5
        
        # 检查保健食品特征
        health_food_keywords = ["保健食品", "保健功能", "功能声称", "营养成分"]
        if any(keyword in text_data for keyword in health_food_keywords):
            scene_type = "广告"
            product_type = "保健食品"
            specific_scene = "保健食品广告审查"
            confidence = 0.95
            
        return {
            "scene_type": scene_type,
            "product_type": product_type,
            "specific_scene": specific_scene,
            "confidence": confidence,
            "evidence": [
                {
                    "type": "文本特征",
                    "content": text_data[:200],
                    "reliability": "high"
                }
            ]
        }
        
    except Exception as e:
        logger.error(f"场景识别失败: {str(e)}")
        return {
            "scene_type": "unknown",
            "confidence": 0
        }
```

### 2. ReAct 控制器

ReAct 控制器是系统的核心，负责协调各个模块的工作：

```python
async def _execute_react_loop(self, 
                           prompt: str, 
                           max_steps: int = 5,
                           temperature: float = 0.7,
                           retry_count: int = 3) -> Dict[str, Any]:
    """执行 ReAct 循环"""
    current_prompt = prompt
    history = []
    
    for step in range(max_steps):
        logger.info(f"ReAct 步骤 {step + 1}")
        
        # 获取LLM响应
        for attempt in range(retry_count):
            try:
                response = await llm_chat(current_prompt, temperature=temperature)
                
                # 检查最终答案
                final_result = self._extract_final_answer(response)
                if final_result:
                    final_result["reasoning_process"] = history
                    return final_result
                
                # 解析工具调用
                tool_name, tool_args = await self._parse_latest_plugin_call(response)
                if tool_name:
                    # 执行工具调用并更新历史记录
                    result = await self._execute_tool(tool_name, tool_args)
                    history.append({
                        "step": step + 1,
                        "thought": self._extract_thought(response),
                        "action": f"{tool_name}: {json.dumps(tool_args)}",
                        "result": result
                    })
                    
                    # 更新提示词
                    current_prompt = f"{current_prompt}\nObservation: {json.dumps(result)}"
                    break
                    
            except Exception as e:
                logger.error(f"步骤执行失败: {str(e)}")
                if attempt < retry_count - 1:
                    await asyncio.sleep(1)
                    continue
                
    return {
        "error": "未能获取有效的分析结果",
        "is_valid": False,
        "reasoning_process": history
    }
```

### 3. 规则解析模块

规则解析模块将原始法规文本转换为系统可执行的结构化规则：

```python
async def parse_raw_rule(self, raw_text: str, max_retries: int = 3) -> Dict[str, Any]:
    """解析原始法规文本为结构化规则"""
    for attempt in range(max_retries):
        try:
            # 构建提示词
            prompt = self._prepare_rule_prompt(raw_text)
            
            # 调用LLM解析规则
            response = await llm_chat(prompt, temperature=0.7)
            
            # 清理和验证结果
            json_text = self._clean_json_string(response)
            parsed_rules = json.loads(json_text)
            
            if self._validate_rules(parsed_rules):
                return parsed_rules
                
        except Exception as e:
            logger.error(f"规则解析尝试 {attempt + 1} 失败: {str(e)}")
            
    return {"error": "规则解析失败", "rules": []}
```

## 最佳实践

在实践中，我们总结出以下几点重要经验：

### 1. 提示词工程

良好的提示词设计对系统性能至关重要：

- 使用结构化的提示词模板
- 清晰定义输入输出格式
- 包含充分的上下文信息
- 提供具体的示例说明

### 2. 错误处理

健壮的错误处理机制是保证系统稳定性的关键：

- 实现多层级的异常捕获
- 提供合理的重试机制
- 保存详细的错误日志
- 设计优雅的降级策略

### 3. 性能优化

针对系统性能，我们实施了以下优化措施：

- LLM 调用参数优化
- 响应结果缓存
- 并发请求控制
- 资源使用监控

## 实际应用案例

### 保健食品广告审核

系统成功应用于保健食品广告的自动审核：

1. 场景识别：
```json
{
    "scene_type": "广告",
    "product_type": "保健食品",
    "specific_scene": "保健食品广告审查",
    "confidence": 0.95
}
```

2. 规则匹配：
```json
{
    "rule_matches": [
        {
            "rule_id": "RULE_CONTENT_001",
            "matched": true,
            "reason": "广告内容符合注册证书",
            "evidence": "批准文号核实通过"
        }
    ]
}
```

3. 审核结果：
```json
{
    "is_compliant": true,
    "confidence": 0.92,
    "suggestions": [
        {
            "target": "警示语",
            "suggestion": "建议增加显著性"
        }
    ]
}
```

## 未来展望

系统还有以下几个方向可以继续改进：

1. 模型升级
   - 使用更新的 LLM 模型
   - 引入领域特定的微调
   - 增强多模态处理能力

2. 功能扩展
   - 支持更多文档类型
   - 增加规则自动更新
   - 提供审核报告生成

3. 性能提升
   - 优化响应速度
   - 提高并发处理能力
   - 增强系统可扩展性

## 总结

本文详细介绍了一个基于 LLM 的智能广告审核系统的设计与实现。系统通过 ReAct 架构实现了复杂任务的智能处理，结合规则引擎和多模态分析提供了高效准确的审核服务。在实践中，系统展现出良好的性能和可靠性，为广告审核自动化提供了一个可行的解决方案。

主要技术亮点包括：

1. ReAct 架构实现智能决策
2. 多模态分析提升准确性
3. 灵活的规则引擎设计
4. 健壮的错误处理机制

通过这个系统，我们证明了 LLM 在特定领域应用中的巨大潜力，相信随着技术的不断发展，类似的智能系统将在更多领域发挥重要作用。