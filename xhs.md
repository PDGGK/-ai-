下面给你一份**最新、完整的 6 篇系列文章**，在之前的基础上**重新加入了“为什么选择 Qwen”**、**与阿里合作**、**百炼大模型 POC 项目**等关键信息，特别放在了 **【系列帖 5】** 中专门讲模型选型的部分。这样你在小红书发文时，就不会遗漏这些重要背景了。其余部分大体保持原有的结构、语言风格和互动方式，方便你发布。

> **温馨提示**：  
> - 如果觉得篇幅过长，可再进行适度精简，或拆分为更多小篇章发布。  
> - 在合适位置插入相关截图、流程图、对比图，以增强可读性。

---

## **【系列帖 1】项目背景与初期挑战：海量文档与多模态审核的难题**

 
大家好，以这个帖子为起点，开始分享一下长达三个月的实习。
我们要解决的不是“一两个文件”的小场景，而是**一次就可能有几十上百页资料**、各种授权、包装、海报、多段法条……这个“智能审核”项目到底怎么做？先和大家分享一下背景与初期踩坑！

---

### 为什么要做海量文档“智能审核”？

- **行业痛点**  
  - 药品、医疗器械、保健食品、特殊医学用途配方食品等领域，合规要求繁琐。企业想投放广告，需要提交许多资料：营业执照、商标授权、包装图、说明书、海报……人工审核员一不留神就漏审，工作量也相当大。  
- **数洞项目目标**  
  - 构建**多模态智能审核系统**：自动识别文件中的关键信息（文字、logo、批号、成分、宣传语等），对照法规条文或客户自定义规则进行审查，快速发现潜在违规点。

> **小花絮**：我原以为只要跑跑NLP就OK，结果发现资料五花八门，既有PDF、图片，也有授权书、委托书、营业执照……第一次见那么复杂的场景，瞬间“涨姿势”。

---

### 初期挑战：LangChain + FastChat 不堪重负

- **并发与性能**  
  - 一次审核可能要并行OCR、语义分析、Logo比对……FastChat的显存管理跟不上，常常溢出或卡死。  
- **不支持新模型**  
  - FastChat 停止维护，我们迫切需要多模态（VL）模型，但无法升级接入。  
- **维护性差**  
  - Bug无人修，系统频频崩溃，离上线商用还有巨大差距。

---

### 我学到的第一课：先问需求本质，而非盲目实现

> 有次客户说：“想对所有文件都做全检，包括一些无关图片或表格。”  
> - 我差点就全盘接收，想加流程。但我忽然想到：“**有必要吗？**”  
> - 沟通后才明白他们只想核对包装logo与海报是否一致，那些无关资料根本不需处理。  
> - **启示**：听到需求时，别急着实现，先搞清对方的真正痛点，省下大量无用功。

**团队协作**：过程中我也学到，遇到Bug或需求不清晰时，多和后端、算法、法务沟通，避免独自钻牛角尖。

---

**小结**  
> 鉴于FastChat无法支撑多模态高并发，我们后来自研框架，并切换到底层部署：xinterface + xinference。下一篇聊聊如何做技术转型，顺利支撑海量文档和新模型的调用。

---

#### \[互动\]
> **你在工作或学习中，有碰到过“客户提过度需求”或“需求定义不清”的惨痛经历吗？**来评论区聊聊吧～

---

## **【系列帖 2】从LangChain到自研框架：告别老依赖，拥抱高并发与新模型**

**导语**  
上一期说到，LangChain + FastChat难以跑大规模并行，想升级VL模型也无从下手。团队决定自研框架，并用 **xinterface + xinference** 替换FastChat。今天就来说说这个技术转型的思路与成果～

---

### \[1\] 自研框架思路：微服务 + 可插拔工具

1. **微服务架构**  
   - 把系统拆成“文本审核”“图像审核”“规则管理”“缓存/哈希”等服务，API互调。避免单体式越写越臃肿，也便于扩展。  
2. **可插拔工具链**  
   - OCR、图像相似度、Logo比对、哈希校验等都做成独立插件，需要什么就挂载什么，维护起来更灵活。

---

### \[2\] 底层部署：xinterface + xinference

- **xinterface**  
  - 更灵活的模型接入层，想用多大的语言模型、不同版本的VL模型都可轻松挂载，不再受FastChat限制。  
- **xinference**  
  - GPU并发与显存管理更高效，适合多模态高并发场景。

**成果**  
- **响应时间**：从平均1.5秒降到100ms左右  
- **并发能力**：处理量大增，3-5倍吞吐量提升  
- **维护性**：可随时接入新模型，减少频繁报错或Bug。

---



## **【系列帖 3】多领域广告审核：绝不是只看Logo这么简单！**

**导语**  
广告审核在数洞项目中是最典型却也最复杂的场景。以药品、医疗器械、保健食品、特医食品为例，光是法规就有《广告法》、《药械广审管理暂行办法》等，再加上地方规章和客户自定义条例，可能高达数百或上千条！今天分享一下我们在这块是怎么面对的。

---

### \[1\] 法规来源

- **国家层面**  
  - 如《广告法》、《药械广审管理暂行办法》等。  
- **地方性法规**  
  - 不同省市或特殊区域的补充规定。  
- **客户自定义条款**  
  - 大型企业常在法定要求之外增加内部红线，合规门槛更高。

---

### \[2\] 文件类型

- **营业执照、商标授权、生产许可**  
  - 用于验证企业主体及产品合法性。  
- **包装图、海报、宣传文案**  
  - 各种图片、PDF，需要OCR或图像识别对照关键标识。  
- **PDF说明书**  
  - 动辄十多页，广告宣称不可超出说明书范围。  
- **委托书、代理文件**  
  - 确认代理人是否合法授权，文件是否真实有效。

---

### \[3\] 人工难点：远超「logo & 文案」检查

1. **规则条目多且细**  
   - 处方药广告须显著标明“仅供医学专业人士阅读”，OTC广告需“请按说明书使用”，保健食品严禁暗示治疗功能等。  
2. **多文档多轮比对**  
   - 包装 vs. 海报、审查表 vs. 实际发布样件、说明书 vs. 宣传语……跨文件OCR+文本解析，人工易疏漏。  
3. **版面繁琐 & 文本复杂**  
   - PDF分多页、表格跨页、盖章勾选等处理难度高，且要检测禁用词、越范围宣传等。  
4. **海量提交 & 易漏判**  
   - 一次可提交十几份文件、几十条法规要对照，人工作业负担大，极易出现漏判或误判。

---

*通过这些要点可见，广告审核在药械保健领域并非简单“扫logo、看文案”，而是多文件、多规则、多轮核对相互交叉，难度远超想象。*

### \[4\] 我们的多模态 + Agent 组合拳

1. **VL模型（视觉-语言）**  
   - 识别包装、海报、PDF文件中的图文要素，如logo、标识、勾选框等。  
2. **LLM（大语言模型）**  
   - 分析法规条文，判断广告是否“越范围宣传”或缺少法定提示。  
3. **Agent**  
   - 动态调用OCR、相似度检测等插件，多轮推理完成大多数自动化审核工作。

---

### \[5\] 项目成果

- **减少审核员**：人工只需复核疑难点，常规场景AI可自行判定；  
- **审核时长**：从2-3天缩短到数小时；  
- **合规率**：禁用词、缺失标识、越权宣传等识别更准，也避免企业被罚。

**小结**  
> 多领域广告审核，法规与文档都非常繁琐，绝不是“看看logo、扫扫文本”就能搞定。下一篇再看“规则解析器 + ReAct”如何支持如此海量需求，让大模型自动调度流程。

---

#### \[互动\]
> **你有没有因广告审核的繁琐程度而感到意外？**评论区聊聊你的看法吧～


---


## **【系列帖 4】规则解析器 + ReAct：不用手写上千条法规流程，AI自驱动审核**

**导语**  
法规多达上千条，客户还要加自己内部审查条款，如果程序员一个个写到代码里，简直崩溃。数洞项目用了“规则解析器 + ReAct”思路，让大模型在读取法规后能自动决定调用哪些插件，不用我们写死流程。

---

### \[1\] 规则解析器：把法条转成JSON

- **痛点**  
  - 法规更新、客户改需求都很频繁，硬编码会变“屎山”，很难维护。  
- **做法**  
  - 把法规拆成一个个“审核点”，用JSON保存，如“必须检查商标授权”“logo与海报一致性”“禁用词检测”等。  
  - 客户要加自己规定，也能直接写进JSON，后端代码几乎不用动。

---

### \[2\] ReAct：大模型当“审核流程大脑”

- **传统方式**  
  - 工程师手写一堆if-else：“先OCR→再logo比对→再文本检索……”，一条条法规太多了。  
- **ReAct**  
  - 大模型根据“规则解析器”给出的JSON，自动决定要先调用OCR，还是logo比对、哈希校验……灵活组合工具完成审核。法规更新也不怕。

> **案例**：规则里说“要检查包装logo与文案对应”，ReAct就会先调图像比对插件，再调用文本分析插件，对结果做整合，最后给出结论。

---

### \[3\] 个人体会：质疑需求并了解后端设计

> 有后端同事想在解析器数据库里加“无意义对象”，我一开始以为是“浪费资源”。  
> - 结果问下来才知，这能与旧数据库结构对接，并让ReAct精确调度指定规则，避免破坏测试通过的部分。  
> - **提醒**：很多技术需求背后都有历史包袱或兼容考虑，不要盲目拒绝，先问为什么。

---

### \[4\] 结果：覆盖率高 & 维护量低

- **99% 场景覆盖**：只要法条或需求写进JSON，大模型就能拼接工具执行。  
- **客户可自定义**：无需程序员每次手写逻辑，后续迭代省时省力。  
- **开发更灵活**：前端、后端、算法各司其职，大模型统一调度工具，上千条法规也能轻松覆盖。

**小结**  
> 规则解析器+ReAct 让AI像个“审核专家”，在法规海洋里自如游泳。下一篇再聊聊我们如何对比 GPT-4.0、Claude 3.5 等闭源模型，以及为什么最终选择了 Qwen 系列并做深度场景化优化。

---

#### \[互动\]
> **你觉得“AI自己决定调用哪些工具”靠谱吗？**评论区聊聊你的看法～

---

## **【系列帖 5】模型选型：Qwen 系列 vs GPT/Claude 等闭源模型**

**导语**  
市面上闭源大模型（如 GPT-4.0、Claude 3.5）评测分数很高，但在“海量文档、多法条、多工具协同”场景下，却无法轻松跑通全流程。我们之所以能反超，靠的是**场景化深度优化 + 工具链**思路。并且，我们在内部测试了多家模型，最终选择了**阿里 Qwen 系列**（Qwen2 VL 72B + Qwen2.5 32B），这里就来详细说说原因。

---

### \[1\] 闭源天花板模型的短板

- **无法直接处理签名盖章、手写体、勾选框**  
  - 像 GPT-4.0、Claude 等，都需要OCR或图像切割，否则读不懂这些“非标准数据”。  
- **法规与自定义规则复杂**  
  - 光通用理解能力不够，还要调用logo比对、哈希校验等外部工具，闭源模型难以实现“可插拔”。  
- **私有化与安全**  
  - 很多企业倾向于本地部署，闭源模型常见的高成本、数据安全问题难以解决。

> **最关键**：它们没法自由调用我们那套“工具链”，无法做多步合规检查，中途就会卡住或产出错误。

---

### \[2\] 为什么最终选择**Qwen**系列？

我们一开始也对比过 **Meta 的 Llama 3.2 Vision**、清华的 GLM4v 等开源模型，还试了下 GPT/Claude 等闭源API，但最终选定阿里的Qwen，主要有以下考虑：

1. **大公司支持**  
   - 阿里不太可能轻易放弃自家模型，后续更新和维护更稳定。  
2. **公司与阿里合作**  
   - 我们有一个**百炼大模型 POC**项目在合作，双方沟通成本低，能得到更多技术支持。  
3. **对中文优化深**  
   - Qwen系列对中文场景做了重点训练，识别手写字体等效果更适合国内业务，虽然评测分数不是最顶尖，但对我们项目足够。  
4. **可与OCR等前期预处理结合**  
   - 如果Qwen暂时识别不佳，我们还能通过OCR切分或图像增强，让输入更干净，配合ReAct调度，准确率更高。

---

### \[3\] 测试结果：我们更适配复杂合规流程

- **无法跑通 vs. 完整跑完**  
  - GPT-4.0/Claude 在多文档、多步骤场景常被卡住，而Qwen借助**xinterface + xinference**和我们的可插拔工具链，能从头到尾跑通。  
- **准确率更高**  
  - 在指定场景下，Qwen + 预处理 + 规则解析器，比“裸跑GPT”或“纯Claude”高出 20-30%准确度。  
- **落地优势**  
  - 本地化部署、阿里官方支持，搭配**百炼大模型 POC**项目，让整体方案更稳妥，也更符合企业内网安全要求。

**小结**  
> 顶尖模型分数很高，但不见得适合特殊场景；Qwen和我们在OCR、工具链、规则解析器等工程环节结合紧密，反而效果更好。最后一篇我再总结一下我的实习心得，尤其是“预处理思维”“质疑需求”“团队协作”等核心理念。

---

#### \[互动\]
> **你更看好哪家大模型？** #GPT4 #Claude #Qwen 还是其他？评论区见～

---

## **【系列帖 6】实习总结：预处理、质疑需求、与团队协作——三大关键收获**

**导语**  
三个月的实习很快结束，从一开始的“海量文档轰炸”，到后来熟悉多模态、规则解析、ReAct、Qwen等技术，我在数洞项目中收获巨大。最后一篇就聊聊我最深刻的**三大收获**，希望能给大家带来一些启发。

---

### \[1\] 收获一：**预处理（前置化）**——与大模型做切割

- **原因**  
  - 大模型输出存在随机性、黑箱性，不可能次次一致。  
- **好处**  
  - 能前置解决的事（OCR、哈希、pdf切分、logo定位），就不要让模型“猜”。可维护性、准确率明显提升。  
- **工程意义**  
  - 也方便做缓存，减少重复调用大模型的算力消耗。

---

### \[2\] 收获二：**先质疑需求，再确定实现方式**

- **客户 / 同事提出需求**时，先搞明白他们要解决的核心痛点。  
  - 有人喊“要跑全量检测”，其实只关心logo或文案一致性；不用盲目全部处理。  
- **后端的历史包袱**  
  - 想加“无意义对象”？原来是为了兼容旧数据库，确保ReAct流程平稳衔接。这也是合理设计的一种体现。

---

### \[3\] 收获三：**团队协作与场景化落地**

- **AI 落地不是“一个大模型”就行**  
  - 要结合法务、后端、算法、产品多方需求，还得考虑历史数据库、客户自定义规则等。  
- **场景化**  
  - 我们做了大量工程优化、可插拔工具和规则解析，这比单纯追求“排行榜最高分”的模型更重要。

---

**小结**  
> 这三个月的实习让我对AI项目有了全新认识：**先问清需求**、**前置化解决可控问题**、**灵活组合工具**，再结合“**整体的合理性**”理念，胜过盲目追求单点最高分。希望这些心得对你有帮助，也祝你在自己的项目中持续迭代成长！

#### 有位前辈提到  
> 在设计和管理复杂系统时，应注重**整体的合理性**，而非过分追求**单个部分的先进性**。

在我们的AI审核项目中恰如其分：只有统筹业务、技术、法务、数据安全等多方需求，把各模块协同好，才能让系统真正落地并产生价值。

---

#### \[互动\]
> **你在实习或工作中，学到的最关键思维是什么？**欢迎评论区分享，一起交流～

---

## **发帖建议**

1. **排版与图片**  
   - 在小红书用Markdown/富文本，分段合理，加粗要点；插入OCR对比、ReAct流程图、Qwen与GPT对比图等，增强可读性。  
2. **标签与话题**  
   - 建议 `#AI落地`、`#预处理`、`#ReAct技术`、`#Qwen模型`、`#百炼大模型POC`、`#多模态`、`#实习心得` 等，方便目标读者发现。  
3. **分6次发**  
   - 一周1-2篇保持账号活跃度，让粉丝能系统了解你的实习经历与技术成长。

---
